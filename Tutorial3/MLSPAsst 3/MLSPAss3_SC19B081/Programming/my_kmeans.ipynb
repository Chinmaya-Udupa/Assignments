{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC19B081\n",
    "\n",
    "Write a function my_kmeans.ipynb to implement a basic version of the K-means algorithm.\n",
    "\n",
    "Inputs:\n",
    "- an NxD data matrix A where N is the number of samples and D is the dimensionality of your feature representation.\n",
    "- the number K denoting how many clusters to output, and\n",
    "- a value iters saying how many iterations to run for K-means.\n",
    "\n",
    "Outputs:\n",
    "- an Nx1 output ids containing the data membership IDs of each \n",
    "sample (denoted by indices randing from 1 to K, where K is the \n",
    "number of clusters),\n",
    "- a KxD matrix means containing the mean/center for each cluster, \n",
    "and\n",
    "- a scalar ssd measuring the final SSD error of the clustering, i.e. the \n",
    "sum of the squared distances between points and their assigned \n",
    "means, summed over all clusters.\n",
    "\n",
    "Instructions:\n",
    "1. [5 pts] First, initialize the cluster means randomly. Get the range of \n",
    "the feature space, separately for each feature dimension (compute \n",
    "max and min and take the difference) and use this to request random \n",
    "numbers in that range. Look for the function for generating random \n",
    "numbers .\n",
    "2. [5 pts] Then, iterate over the following two steps. The first step is to \n",
    "compute the memberships for each data sample. Write a function \n",
    "(similar to Matlab function pdist2) to efficiently compute \n",
    "distances (check its documentation to see what inputs it expects). \n",
    "Then for each sample, find the min distance and the cluster that gives \n",
    "this min distance.\n",
    "3. [5 pts] The second step is to recompute the cluster means, simply \n",
    "taking the average across samples assigned to that cluster, for each \n",
    "feature dimension.\n",
    "4. [5 pts] Finally, compute the overall SSD error. It helps to keep track \n",
    "of the min distance per sample as you iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist2(ref,samples):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - ref:  reference matrix of size KxD\n",
    "    - samples: sample matrix of size NxD\n",
    "    \n",
    "    Returns:\n",
    "    - dist: Euclidean distance between the K ref points and N samples,\n",
    "            size K,N\n",
    "    \n",
    "    \"\"\"\n",
    "    K,D1 = ref.shape\n",
    "    N,D2 = samples.shape\n",
    "    assert D1==D2, 'Dimensions of reference and samples dont match' \n",
    "    dist = np.zeros([K,N])\n",
    "    for i in range(K):\n",
    "        for j in range(N):\n",
    "            dist[i,j] = np.linalg.norm(ref[i,:] - samples[j,:])\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(A, K, iters):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - A: matrix A of size NxD, where N is number of samples and D is the dimensionality of Feature representation\n",
    "    - K: number of clusters\n",
    "    - iters: number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    - cluster_id: Nx1 vector, with class labels in it, class labels : 1 to K\n",
    "    - cluster_center: KxD matrix containing center of each cluster\n",
    "    - ssd: sum of squared distances  \n",
    "     \n",
    "    \"\"\"\n",
    "    N,D = A.shape\n",
    "    A_max = np.max(A,axis=0)\n",
    "    A_min = np.min(A,axis=0)\n",
    "    cluster_center = A_min + (A_max-A_min)*np.random.rand(K,D)\n",
    "    distances = np.zeros([K,N])\n",
    "    for i in range(iters):\n",
    "        distances = pdist2(cluster_center,A)\n",
    "        cluster_id = np.argmin(distances,axis=0)\n",
    "        classifying_matrix = np.zeros([N,D,K])\n",
    "        id_count = np.zeros(K,dtype=int)\n",
    "        for i,id in enumerate(cluster_id):\n",
    "            id_count[id] += 1\n",
    "            classifying_matrix[id_count[id]-1,:,id] = A[i,:]\n",
    "        for i in range(K):\n",
    "            cluster_center[i,:] = np.sum(classifying_matrix[:,:,i],axis=0)/id_count[i]\n",
    "    \n",
    "    ssd = np.sum((pdist2(cluster_center,A))**2)\n",
    "     \n",
    "    return cluster_id,cluster_center,ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.zeros([4,10,2])\n",
    "np.mean(a[:,:,1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2d74e9454ee5caf31952733146ee00f8154502441cd797a56b6df69d60e3d36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
